from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings   
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.retrievers import ParentDocumentRetriever
from langchain.schema import Document
import pandas as pd
import pymysql
from langchain_community.storage import SQLStore
from langchain_huggingface import HuggingFaceEmbeddings
import os
import warnings
import chromadb
warnings.filterwarnings('ignore')



def save_df(host,port,username,password,db_name):
    conn = pymysql.connect(host=host, port=port, user=username, password=password, db=db_name)
    df = pd.read_sql('SELECT * FROM íŒë¡€', conn)
    df.to_csv('íŒë¡€.csv', index=False)
    conn.close()
    

def create_db(base_db_dir='./db'):
    # íŒë¡€.csv íŒŒì¼ ì½ê¸°
    df_íŒë¡€ = pd.read_csv('íŒë¡€.csv',nrows=10)

    
    # ê¸°ì¡´ ë²¡í„° DBê°€ ì¡´ì¬í•˜ë©´ ì‚­ì œ
    try:
        client = chromadb.PersistentClient(path=base_db_dir)
        client.delete_collection(name='LAW_RAG')
        print(f"[ì‚­ì œ] ê¸°ì¡´ ë²¡í„° DBê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤: {base_db_dir}")
    except Exception as e:
        print(f"[ê²½ê³ ] ê¸°ì¡´ DB ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # DB ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(base_db_dir, exist_ok=True)
    
    # Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    print('Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ ìƒì„± ì¤‘...')
    docs = []
    for i, row in df_íŒë¡€.iterrows():
        metadata = {
            "source": row['íŒë¡€ì¼ë ¨ë²ˆí˜¸'],
            'case_type': row['ì‚¬ê±´ëª…']
        }
        doc = Document(page_content=str(row['íŒë¡€ë‚´ìš©']), metadata=metadata)
        docs.append(doc)
    print('Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ')
    model_name = 'intfloat/multilingual-e5-large-instruct'
    hf_embeddings = HuggingFaceEmbeddings(model_name=model_name)
    
    print('í…ìŠ¤íŠ¸ ë¶„í•  ì¤‘...')
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1500,
        chunk_overlap=300
    )
    
    split_docs = text_splitter.split_documents(docs)
    print('í…ìŠ¤íŠ¸ ë¶„í•  ì™„ë£Œ')
    
    # ìì‹ ì²­í¬ë¥¼ ì €ì¥í•  ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
    print('ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘...')
    vectorstore = Chroma.from_documents(
        documents=split_docs,
        embedding=hf_embeddings,
        collection_name='LAW_RAG',
        persist_directory=base_db_dir
    )

    vectorstore.persist()
    
    print(f"[ì™„ë£Œ] íŒë¡€ {len(docs)}ê±´ì´ ì›ë³¸ê³¼ ì²­í¬ë¡œ ë¶„ë¦¬ë˜ì–´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ì›ë³¸ ë¬¸ì„œ: SQL í…Œì´ë¸” 'íŒë¡€_ì›ë³¸'")
    print(f"ì²­í¬ ë²¡í„°: {base_db_dir}/LAW_RAG")
    
def retrieve_db(query,base_db_dir='./db'):
    df=pd.read_csv('íŒë¡€.csv',nrows=10)
    vectorstore = Chroma(
        persist_directory=base_db_dir,
        embedding_function=HuggingFaceEmbeddings(model_name='intfloat/multilingual-e5-large-instruct'),
        collection_name='LAW_RAG'
    )
    
    retriever = vectorstore.as_retriever(search_kwargs={"k": 1})
    print('ë²¡í„°ìŠ¤í† ì–´ ê²€ìƒ‰ ì¤‘...')
    results = retriever.invoke(query)
    
    # ê²°ê³¼ ì¶œë ¥
    for i, doc in enumerate(results):
        meta = doc.metadata
        print(f"\nğŸ” [ê²°ê³¼ {i+1}]")
        print(f"â–¶ íŒë¡€ì¼ë ¨ë²ˆí˜¸ : {meta['source']}")
        print(f"â–¶ ì‚¬ê±´ëª… : {meta['case_type']}")
        print("â–¶ ìœ ì‚¬ ë¬¸ë‹¨:", doc.page_content.strip())
        print('ì›ë³¸ íŒë¡€:',df.loc[df['íŒë¡€ì¼ë ¨ë²ˆí˜¸'] == meta['source']]['íŒë¡€ë‚´ìš©'].values[0])
        print("\n" + "="*50)