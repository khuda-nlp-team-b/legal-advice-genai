from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
import pandas as pd
import pymysql
from langchain.schema import Document
import os

def load_df(host, port, username, password, db):
    conn = pymysql.connect(host=host, port=port, user=username, password=password, db=db)
    df_íŒë¡€ = pd.read_sql('SELECT * FROM íŒë¡€ where ì‚¬ê±´ì¢…ë¥˜ëª… = \'í˜•ì‚¬\' limit 300;', conn)
    conn.close()
    return df_íŒë¡€

case_type_list = [
        'í˜•ì‚¬', 'ë¯¼ì‚¬', 'ì¼ë°˜í–‰ì •', 'ì„¸ë¬´', 'íŠ¹í—ˆ', 'ê°€ì‚¬', 'ê°€ì‚¬_ìƒì†', 'ê°€ì‚¬_ì´í˜¼', 'ê°€ì‚¬_ì¬ì‚°ë¶„í• ',
        'êµ­ê°€ë°°ìƒ', 'ê·¼ë¡œ_ì‚°ì¬', 'ê·¼ë¡œ_ì„ê¸ˆ', 'ê¸°ì—…_ê³µë™í–‰ìœ„', 'ê¸°ì—…_ê³µì •ìœ„', 'ê¸°ì—…_í•´ê³ ',
        'ì œì¡°ë¬¼_ì±…ì„_ë¯¼ì‚¬', 'í–‰ì •_ì‹œì •ëª…ë ¹', 'í–‰ì •_ì •ë³´ê³µê°œ', 'í–‰ì •ê°•ì œ', 'í–‰ì •', 'í˜•ì‚¬_êµí†µ', 'í˜•ì‚¬_í­í–‰'
    ]

def get_case_type_index(case_type):
    try:
        return case_type_list.index(case_type)
    except ValueError:
        raise ValueError(f"[ì˜¤ë¥˜] '{case_type}' ëŠ” ìœ íš¨í•œ ì‚¬ê±´ ìœ í˜•ì´ ì•„ë‹™ë‹ˆë‹¤.")

def build_rag_db_by_case_type(df_íŒë¡€, case_type, api_key, base_db_dir='./db'):
    """
    íŠ¹ì • ì‚¬ê±´ ìœ í˜•ì— í•´ë‹¹í•˜ëŠ” íŒë¡€ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì—¬ RAGìš© ë²¡í„° DBë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        df_íŒë¡€ (pd.DataFrame): íŒë¡€ ë°ì´í„°í”„ë ˆì„ (í•„ìˆ˜ ì»¬ëŸ¼: 'ì‚¬ê±´ì¢…ë¥˜ëª…', 'íŒë¡€ë‚´ìš©')
        case_type (str): ì˜ˆ: 'í˜•ì‚¬', 'ë¯¼ì‚¬', 'ì¼ë°˜í–‰ì •' ë“±
        api_key (str): OpenAI API í‚¤
        base_db_dir (str): ê¸°ë³¸ DB ì €ì¥ ê²½ë¡œ

    Returns:
        db (Chroma): ìƒì„±ëœ Chroma ë²¡í„° DB ê°ì²´
    """

    # 1. í•´ë‹¹ ì‚¬ê±´ ìœ í˜•ì— í•´ë‹¹í•˜ëŠ” í–‰ í•„í„°ë§
    filtered_df = df_íŒë¡€[df_íŒë¡€['ì‚¬ê±´ì¢…ë¥˜ëª…'] == case_type].reset_index(drop=True)
    if filtered_df.empty:
        raise ValueError(f"[ê²½ê³ ] '{case_type}' ìœ í˜•ì— í•´ë‹¹í•˜ëŠ” íŒë¡€ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # 2. Document ê°ì²´ë¡œ ë³€í™˜
    documents = []

    '''  for i, content in enumerate(filtered_df['íŒë¡€ë‚´ìš©']):
            doc_id = f"{case_type}_{i}"
            doc = Document(page_content=content, metadata={"source": doc_id})
            documents.append(doc)
            original_text_map[doc_id] = content'''
        
    for i, row in filtered_df.iterrows():
        metadata = {
            "source": row['íŒë¡€ì¼ë ¨ë²ˆí˜¸'],
            'case_type': row['ì‚¬ê±´ì¢…ë¥˜ëª…'],
            'full_content': row['íŒë¡€ë‚´ìš©']
        }
        doc = Document(page_content=row['íŒë¡€ë‚´ìš©'], metadata=metadata)
        documents.append(doc)

    # 3. í…ìŠ¤íŠ¸ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=700,
        chunk_overlap=100,
        encoding_name='cl100k_base'
    )
    split_docs = text_splitter.split_documents(documents)

    # 4. DB ê²½ë¡œ ì§€ì • ë° ë²¡í„° ì €ì¥
    db_dir = os.path.join(base_db_dir, f"chromadb_law_{case_type}")
    os.makedirs(db_dir, exist_ok=True)

    embeddings_model = OpenAIEmbeddings(api_key=api_key)

    case_num = get_case_type_index(case_type)

    db = Chroma.from_documents(
        documents=split_docs,
        embedding=embeddings_model,
        collection_name=f'LAW_RAG_{case_num}',
        persist_directory=db_dir,
        collection_metadata={'hnsw:space': 'cosine'}
    )

    print(f"[ì™„ë£Œ] '{case_type}' ìœ í˜•ì˜ íŒë¡€ {len(documents)}ê±´ì´ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def search_law_rag(query, case_type, api_key, k=1):
    """
    íŠ¹ì • ì‚¬ê±´ ìœ í˜• DBì—ì„œ ì§ˆì˜ë¥¼ ê²€ìƒ‰í•˜ì—¬ ìœ ì‚¬ ë¬¸ë‹¨ê³¼ ì „ì²´ íŒë¡€ ì›ë¬¸ì„ ì¶œë ¥í•©ë‹ˆë‹¤.

    Args:
        query (str): ì‚¬ìš©ì ì§ˆë¬¸
        case_type (str): ì‚¬ê±´ ìœ í˜• (ì˜ˆ: 'í˜•ì‚¬', 'ë¯¼ì‚¬', ...)
        api_key (str): OpenAI API í‚¤
        text_map (dict): {source_id: íŒë¡€ ì›ë¬¸} í˜•íƒœì˜ dict
        k (int): ê²€ìƒ‰í•  ìœ ì‚¬ ë¬¸ë‹¨ ê°œìˆ˜ (ê¸°ë³¸ê°’ 1)
    """

    # ì‚¬ê±´ ìœ í˜• ë²ˆí˜¸ â†’ collection_name ìƒì„±
    case_num = get_case_type_index(case_type)

    if not os.path.exists(f"./db/chromadb_law_{case_type}"):
        raise ValueError(f"[ì˜¤ë¥˜] '{case_type}' ìœ í˜•ì˜ DBê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¨¼ì € DBë¥¼ ìƒì„±í•˜ì„¸ìš”.")
    
    # DB ë¡œë“œ
    db = Chroma(
        persist_directory=f"./db/chromadb_law_{case_type}",
        collection_name=f"LAW_RAG_{case_num}",
        embedding_function=OpenAIEmbeddings(api_key=api_key)
    )

    '''    # ìœ ì‚¬ë„ ê²€ìƒ‰
        results = db.similarity_search(query, k=k, filter={"case_type": case_type})'''  
    
    retriever = db.as_retriever(
        search_type = 'similarity', search_kwargs={'k': k}
        )
    results = retriever.invoke(query)
    

    # ê²°ê³¼ ì¶œë ¥
    for i, doc in enumerate(results):
        meta = doc.metadata
        print(f"\nğŸ” [ê²°ê³¼ {i+1}]")
        print(f"â–¶ íŒë¡€ì¼ë ¨ë²ˆí˜¸ : {meta['source']}")
        print("â–¶ ìœ ì‚¬ ë¬¸ë‹¨:", doc.page_content.strip())

        print("\nğŸ“„ [ì „ì²´ íŒë¡€ ë‚´ìš©]")
        full_content = meta.get('full_content', 'ì „ì²´ íŒë¡€ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.')
        print(full_content.strip())
        print("\n" + "="*50)
    
