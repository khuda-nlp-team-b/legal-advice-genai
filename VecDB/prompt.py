import os
import argparse
import jinja2
import time
import create_db as cdb                             # â† ì¶”ê°€
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline
from langchain_community.llms import HuggingFacePipeline
from dotenv import load_dotenv
load_dotenv()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1) ê²½ë¡œÂ·í™˜ê²½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_PATH  = os.path.dirname(os.path.abspath(__file__))
PROMPT_DIR = os.path.join(BASE_PATH, "prompts")

# â†“â†“â†“  db_test/<ì—¬ê¸°ì— db ì…ë ¥>  ë¶€ë¶„ë§Œ ë°”ê¿”ì£¼ì„¸ìš” â†“â†“â†“
DB_SUBDIR = "LAW_RAG_TEST_1000_100_openai"
#DB_DIR    = os.path.join(BASE_PATH, "db_test", DB_SUBDIR)
# â†‘â†‘â†‘  db_test/<ì—¬ê¸°ì— db ì…ë ¥>  ë¶€ë¶„ë§Œ ë°”ê¿”ì£¼ì„¸ìš” â†‘â†‘â†‘

OPENAI_KEY = os.getenv("OPENAI_API_KEY")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2) DB ì ‘ì† ì •ë³´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# (create_db.retrieve_db í˜¸ì¶œì„ ìœ„í•´ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •)
HOST        = os.getenv("DB_HOST")
PORT        = int(os.getenv("DB_PORT", 3306))
USER        = os.getenv("DB_USER")
PASSWORD    = os.getenv("DB_PASSWORD")
DB_NAME     = os.getenv("DB_NAME")
BASE_DB_DIR = os.path.join(BASE_PATH, "db_test")   # create_db.pyì˜ base_db_dir ì¸ì

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3) Jinja2 í…œí”Œë¦¿ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
env = jinja2.Environment(
    loader=jinja2.FileSystemLoader(PROMPT_DIR),
    autoescape=False,
    trim_blocks=True,
    lstrip_blocks=True,
)
query_tpl  = env.get_template("query_rewrite.j2")  # í…œí”Œë¦¿ íŒŒì¼ëª…ì´ ì •í™•í•œì§€ í™•ì¸í•˜ì„¸ìš” :contentReference[oaicite:0]{index=0}
answer_tpl = env.get_template("answer_synth.j2")

def get_llm():
    return ChatOpenAI(api_key=OPENAI_KEY, model_name="gpt-3.5-turbo", temperature=0)

def rewrite_query(user_query: str) -> str:
    prompt = query_tpl.render(user_query=user_query)
    llm = get_llm()
    print("ğŸ”„ ì§ˆì˜ ì¬ì‘ì„±(LLM) â€¦", end=" ")
    start = time.perf_counter()
    resp = llm.invoke(prompt)
    print(f"âœ” ({time.perf_counter()-start:.1f}s)")
    return resp.content.strip() if hasattr(resp, "content") else resp.strip()

def run_rag(user_query: str, k: int = 10) -> str:
    # 1) ê²€ìƒ‰ì–´ ì¬ì‘ì„±
    search_query = rewrite_query(user_query)
    print("   â†ª ê²€ìƒ‰ì–´:", search_query)

    # 2) MySQL+Chroma í†µí•© ì „ë¬¸ ì¡°íšŒ (create_db.retrieve_db í˜¸ì¶œ)
    print("ğŸ” MySQL ì „ë¬¸ ì¡°íšŒ ì¤‘â€¦")
    results = cdb.retrieve_db(
        search_query,
        HOST, PORT, USER, PASSWORD, DB_NAME,
        OPENAI_KEY,
        base_db_dir=BASE_DB_DIR
    )

    # 3) ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ ë° í…œí”Œë¦¿ ì ìš©
    if not results or len(results) == 0:
        return "ìœ ì‚¬ íŒë¡€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    # ê°€ì¥ ìœ ì‚¬í•œ íŒë¡€ 1ê±´ë§Œ í™œìš© (í™•ì¥ ê°€ëŠ¥)
    top = results[0]
    context = f"{top['ìœ ì‚¬ë¬¸ë‹¨']} [ref:{top['íŒë¡€ì¼ë ¨ë²ˆí˜¸']}]"
    full_document = top['ì „ë¬¸']

    answer = answer_tpl.render(
        context=context,
        full_document=full_document,
        user_query=user_query
    )
    return answer


def main():
    parser = argparse.ArgumentParser(
        description="íŒë¡€ RAG ê²€ìƒ‰ê¸° (OpenAI ì „ìš©, DB ì¬ìƒì„± ì—†ìŒ)",
        formatter_class=argparse.RawTextHelpFormatter,
    )
    parser.add_argument("query", nargs="*", help="ê²€ìƒ‰í•  ì§ˆë¬¸")
    parser.add_argument("--k", type=int, default=10, help="ê°€ì ¸ì˜¬ ìƒìœ„ ë¬¸ì„œ ìˆ˜")
    args = parser.parse_args()

    if not args.query:
        user_query = input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    else:
        user_query = " ".join(args.query)

    if not user_query:
        parser.error("ì§ˆë¬¸ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    answer = run_rag(user_query, args.k)
    print("\nğŸ“Œ ìµœì¢… ìš”ì•½\n", answer)
    return answer
