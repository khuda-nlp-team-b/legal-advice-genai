import os
import argparse
import jinja2
import time
import utils as u  # ê¸°ì¡´: create_db as cdb
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from dotenv import load_dotenv
load_dotenv()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1) ê²½ë¡œÂ·í™˜ê²½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_PATH = os.path.dirname(os.path.abspath(__file__))
PROMPT_DIR = os.path.join(BASE_PATH, "prompts")
DB_SUBDIR = "LAW_RAG_500_75"
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
BASE_DB_DIR = os.path.join(BASE_PATH, "db_test")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2) DB ì ‘ì† ì •ë³´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
HOST = os.getenv("DB_HOST")
PORT = int(os.getenv("DB_PORT", 3306))
USER = os.getenv("DB_USER")
PASSWORD = os.getenv("DB_PASSWORD")
DB_NAME = os.getenv("DB_NAME")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3) Jinja2 í…œí”Œë¦¿ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
env = jinja2.Environment(
    loader=jinja2.FileSystemLoader(PROMPT_DIR),
    autoescape=False,
    trim_blocks=True,
    lstrip_blocks=True,
)
query_tpl  = env.get_template("query_rewrite.j2")
answer_tpl = env.get_template("answer_synth.j2")

def get_llm():
    return ChatOpenAI(api_key=OPENAI_KEY, model_name="gpt-3.5-turbo", temperature=1)

def run_rag(user_query: str, k: int = 5) -> str:
    # 1) ë²¡í„°ìŠ¤í† ì–´/DBì—ì„œ ìœ ì‚¬ íŒë¡€ ê²€ìƒ‰
    print("ğŸ” ìœ ì‚¬ íŒë¡€ ê²€ìƒ‰ ì¤‘â€¦")
    results = u.retrieve_db(
        user_query,
        HOST, PORT, USER, PASSWORD, DB_NAME,
        k=k,
        base_db_dir = BASE_DB_DIR
    )

    if not results or len(results) == 0:
        return "ìœ ì‚¬ íŒë¡€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    # ê°€ì¥ ìœ ì‚¬í•œ íŒë¡€ 1ê±´ë§Œ ì‚¬ìš© (í™•ì¥ ê°€ëŠ¥)
    top = results[0]
    context = f"{top['ìœ ì‚¬ë¬¸ë‹¨']} [ref:{top['íŒë¡€ì¼ë ¨ë²ˆí˜¸']}]"
    full_document = top['ì „ë¬¸']

    # 2) LLM ë‹µë³€ ìƒì„± (get_llm ì‚¬ìš©)
    print("ğŸ–‹ï¸ ë‹µë³€ ìƒì„± ì¤‘â€¦", end=" ")
    start = time.perf_counter()
    prompt = answer_tpl.render(
        context=context,
        full_document=full_document,
        user_query=user_query
    )
    llm = get_llm()
    result = llm.invoke(prompt)
    print(f"âœ” ({time.perf_counter()-start:.1f}s)")

    return result.content if hasattr(result, "content") else result

def main():
    user_query = input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    answer = run_rag(user_query)
    print("\nğŸ“Œ ìµœì¢… ìš”ì•½\n", answer)
    return answer

if __name__ == "__main__":
    main()
